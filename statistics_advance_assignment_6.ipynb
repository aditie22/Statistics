{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9924ebed-0af7-4791-bb16-adab9e414491",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47209601-f552-404f-bab5-420efe37581d",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical method used to compare means among multiple groups. It's commonly used when you want to determine if there are statistically significant differences between the means of three or more independent (unrelated) groups. To use ANOVA effectively, certain assumptions need to be met. Violations of these assumptions can impact the validity of the results. Here are the assumptions and examples of violations:\n",
    "\n",
    "Assumptions of ANOVA:\n",
    "\n",
    "Independence: The observations in each group are independent of each other and not influenced by the observations in other groups.\n",
    "\n",
    "Normality: The distribution of the residuals (the differences between observed values and the group means) within each group should be approximately normal. This assumption is more crucial when sample sizes are small.\n",
    "\n",
    "Homogeneity of Variance (Homoscedasticity): The variability of the residuals is roughly constant across all levels of the independent variable. In other words, the spread of the residuals should be similar across all groups.\n",
    "\n",
    "Examples of Violations:\n",
    "\n",
    "Independence:\n",
    "\n",
    "Violation Example: Observations taken over time from the same subjects are likely to be correlated, which violates independence.\n",
    "Impact: Correlated observations can lead to incorrect standard errors, inflated significance levels, and incorrect conclusions.\n",
    "Normality:\n",
    "\n",
    "Violation Example: If residuals within groups are heavily skewed or have outliers, the normality assumption might be violated.\n",
    "Impact: Violations can lead to inaccurate p-values and confidence intervals, affecting the overall validity of the ANOVA results.\n",
    "Homogeneity of Variance:\n",
    "\n",
    "Violation Example: Unequal variances in the groups' residuals, where some groups have significantly larger variability than others.\n",
    "Impact: Violations can lead to incorrect F-tests, inflated or deflated Type I error rates, and inaccurate conclusions about group differences.\n",
    "Outliers:\n",
    "\n",
    "Violation Example: Outliers that significantly deviate from the rest of the data within a group.\n",
    "Impact: Outliers can distort the group means, leading to biased results and affecting the statistical significance of differences between groups.\n",
    "Non-Additivity:\n",
    "\n",
    "Violation Example: Interaction effects between factors are present, meaning the effect of one factor on the response variable is dependent on the level of another factor.\n",
    "Impact: Interaction effects can complicate the interpretation of main effects and lead to incorrect conclusions about group differences.\n",
    "It's important to note that ANOVA is robust to violations of assumptions, especially when sample sizes are large. However, when assumptions are severely violated, the results can become unreliable. In such cases, it might be necessary to consider alternative statistical methods or transformations to address the violations and obtain valid conclusions. Additionally, techniques like non-parametric tests or robust ANOVA models can be used as alternatives when assumptions are not met."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae23df4-ca49-4323-9fc1-98fc42899348",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989e789a-61bc-4cc1-937c-5c0d9e8e6f7f",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical technique used to analyze the differences between the means of multiple groups. There are several types of ANOVA, but the three main types are:\n",
    "\n",
    "One-Way ANOVA:\n",
    "One-Way ANOVA is used when you have one independent variable (factor) with three or more levels (groups), and you want to determine if there are any significant differences between the means of these groups. This is suitable when you're comparing a single factor across multiple groups. For example, you might use a One-Way ANOVA to analyze the effects of different teaching methods on student performance by comparing the mean scores of students taught using different methods.\n",
    "\n",
    "Two-Way ANOVA:\n",
    "Two-Way ANOVA involves two independent variables (factors), each with multiple levels, and is used to assess the effects of these two factors on a dependent variable. It's used when you're interested in understanding how two factors interact and influence the dependent variable. For example, you might use a Two-Way ANOVA to analyze the effects of both gender and diet on weight loss, considering whether the impact of diet varies based on gender.\n",
    "\n",
    "Three-Way ANOVA:\n",
    "Three-Way ANOVA extends the concept of Two-Way ANOVA to three independent variables (factors), each with multiple levels. It's suitable when you're investigating the combined effects of three factors on a dependent variable. However, Three-Way ANOVA is less common than One-Way and Two-Way ANOVA due to the complexity it introduces. An example might involve analyzing the effects of different treatments, gender, and age groups on patient recovery time.\n",
    "\n",
    "In summary:\n",
    "\n",
    "Use One-Way ANOVA when you have one factor and you want to compare the means of multiple groups.\n",
    "Use Two-Way ANOVA when you have two factors and you want to study their individual and interaction effects on a dependent variable.\n",
    "Use Three-Way ANOVA when you have three factors and you're interested in analyzing their combined effects on a dependent variable.\n",
    "Each type of ANOVA helps you determine whether the differences in means observed between groups are statistically significant, allowing you to make informed conclusions about the relationships between variables in your study."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5aa1b5-eee3-4128-8d89-99da355b3f2d",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0573701-0419-44fe-b325-5a61baca769d",
   "metadata": {},
   "source": [
    "In Analysis of Variance (ANOVA), the partitioning of variance refers to the breakdown of the total variation observed in a dataset into different components that can be attributed to different sources or factors. ANOVA is a statistical technique used to compare the means of two or more groups, and understanding the partitioning of variance helps in assessing the significance of these group differences and the influence of various factors.\n",
    "\n",
    "There are typically three types of variance components in a one-way ANOVA:\n",
    "\n",
    "Between-Group Variance (Treatment Variance): This variance component represents the variability between the group means. It assesses whether the means of the different groups are significantly different from each other. If the between-group variance is large relative to the within-group variance, it suggests that the groups have significantly different means.\n",
    "\n",
    "Within-Group Variance (Error Variance): This variance component represents the variability within each group. It accounts for the individual differences or random variability that can't be explained by the group means. If the within-group variance is large, it indicates that there is a significant amount of variation within the groups.\n",
    "\n",
    "Total Variance: This is the overall variability in the data and is the sum of the between-group and within-group variances. It provides a baseline measure of the total variability present in the data.\n",
    "\n",
    "The concept of partitioning of variance is important for several reasons:\n",
    "\n",
    "Understanding Group Differences: By breaking down the total variance into between-group and within-group components, ANOVA helps us determine whether the observed group differences are statistically significant. It provides a framework for evaluating whether these differences can be attributed to actual effects or are merely due to random fluctuations.\n",
    "\n",
    "Hypothesis Testing: The partitioning of variance forms the basis for hypothesis testing in ANOVA. The F-test is used to compare the ratio of between-group variance to within-group variance. A large F-statistic indicates that the between-group variance is significantly larger than the within-group variance, suggesting that there are significant group differences.\n",
    "\n",
    "Effect Size: The between-group variance component can be used to calculate effect size measures like eta-squared (η²) or omega-squared (ω²). These measures provide insights into the practical significance of the group differences and help researchers understand the magnitude of the effects.\n",
    "\n",
    "Model Assessment: Understanding the partitioning of variance helps in assessing the adequacy of the statistical model used. If a significant portion of the total variance can be explained by the between-group differences, the model is more likely to be a good fit to the data.\n",
    "\n",
    "In summary, the partitioning of variance in ANOVA allows researchers to quantitatively analyze and interpret the sources of variation in their data, helping them make informed decisions about the significance of group differences and the influence of various factors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9ae4b0-d840-4d58-9b89-54542999658e",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68266f40-f4b6-499c-ab65-fe76e73d7c78",
   "metadata": {},
   "source": [
    "In a one-way ANOVA (analysis of variance), you're dealing with categorical data and want to understand how the variance in a continuous dependent variable is partitioned into different sources of variation. This involves calculating the Total Sum of Squares (SST), the Explained Sum of Squares (SSE), and the Residual Sum of Squares (SSR). Here's how you can calculate these values using Python and the scipy library:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1db8b08c-bb00-4d41-84e6-dde8a6bb63fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 591.7333333333333\n",
      "Explained Sum of Squares (SSE): 538.5333333333334\n",
      "Residual Sum of Squares (SSR): 53.19999999999993\n",
      "\n",
      "One-way ANOVA results:\n",
      "F-statistic: 60.7368421052631\n",
      "p-value: 5.280968618371128e-07\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Generate example data for different groups\n",
    "group1 = np.array([23, 25, 27, 28, 22])\n",
    "group2 = np.array([32, 35, 34, 31, 36])\n",
    "group3 = np.array([18, 20, 19, 17, 21])\n",
    "\n",
    "# Combine all groups into a single array\n",
    "data = np.concatenate((group1, group2, group3))\n",
    "\n",
    "# Calculate the overall mean\n",
    "overall_mean = np.mean(data)\n",
    "\n",
    "# Calculate the Total Sum of Squares (SST)\n",
    "sst = np.sum((data - overall_mean)**2)\n",
    "\n",
    "# Calculate the Explained Sum of Squares (SSE)\n",
    "group_means = [np.mean(group1), np.mean(group2), np.mean(group3)]\n",
    "sse = np.sum([(group_mean - overall_mean)**2 * len(group) for group_mean, group in zip(group_means, [group1, group2, group3])])\n",
    "\n",
    "# Calculate the Residual Sum of Squares (SSR)\n",
    "ssr = sst - sse\n",
    "\n",
    "# Print the calculated values\n",
    "print(\"Total Sum of Squares (SST):\", sst)\n",
    "print(\"Explained Sum of Squares (SSE):\", sse)\n",
    "print(\"Residual Sum of Squares (SSR):\", ssr)\n",
    "\n",
    "# Perform one-way ANOVA using scipy's f_oneway\n",
    "f_statistic, p_value = f_oneway(group1, group2, group3)\n",
    "print(\"\\nOne-way ANOVA results:\")\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ee9f39-f0b9-4440-a0cd-c6d1825e44f2",
   "metadata": {},
   "source": [
    "In this example, I've used three groups (group1, group2, and group3) as an illustration. You would replace these with your actual data. The f_oneway function from scipy.stats can also be used to perform the ANOVA and calculate the F-statistic and p-value.\n",
    "\n",
    "Remember that the p-value from the ANOVA test indicates whether there are significant differences between the group means. If the p-value is below a certain significance level (e.g., 0.05), you might reject the null hypothesis and conclude that at least one group mean is significantly different from the others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b926553-295d-46a3-a1b6-c21e4b0b94fc",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a86e746-9dc1-4ed6-9b54-76cf38444009",
   "metadata": {},
   "source": [
    "In a two-way ANOVA (Analysis of Variance), you're typically dealing with two categorical independent variables and a continuous dependent variable. You want to determine the main effects of each independent variable and also check if there's an interaction effect between them. You can perform this analysis in Python using libraries like NumPy and SciPy. Here's an outline of the steps you would take:\n",
    "\n",
    "Data Preparation: Make sure you have your data properly structured, with one column for each independent variable and one column for the dependent variable.\n",
    "\n",
    "Data Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cc990bb-4f24-47a0-8a33-23110874836a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value for Main Effect 1: 0.5762065515867899\n",
      "P-value for Main Effect 2: 0.10532494223877889\n",
      "P-value for Interaction Effect: 0.11766201798902987\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Example data\n",
    "independent_var1 = np.array(['A', 'B', 'A', 'B', 'A'])\n",
    "independent_var2 = np.array(['X', 'X', 'Y', 'Y', 'X'])\n",
    "dependent_var = np.array([10, 15, 8, 12, 9])\n",
    "\n",
    "# Calculate means for each combination of categories\n",
    "means = []\n",
    "for level1 in np.unique(independent_var1):\n",
    "    for level2 in np.unique(independent_var2):\n",
    "        subset = dependent_var[(independent_var1 == level1) & (independent_var2 == level2)]\n",
    "        mean = np.mean(subset)\n",
    "        means.append(mean)\n",
    "means = np.array(means).reshape(len(np.unique(independent_var1)), len(np.unique(independent_var2)))\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "main_effect_1_data = means.T  # Transpose to get each column as data\n",
    "main_effect_2_data = means     # Each row represents data\n",
    "_, pval_main1 = stats.f_oneway(*main_effect_1_data)\n",
    "_, pval_main2 = stats.f_oneway(*main_effect_2_data)\n",
    "\n",
    "# Calculate interaction effect\n",
    "grand_mean = np.mean(dependent_var)\n",
    "interaction_sum_of_squares = np.sum((means - grand_mean) ** 2)\n",
    "interaction_dof = (len(np.unique(independent_var1)) - 1) * (len(np.unique(independent_var2)) - 1)\n",
    "interaction_mean_square = interaction_sum_of_squares / interaction_dof\n",
    "\n",
    "# Calculate p-value for interaction effect\n",
    "pval_interaction = 1 - stats.f.cdf(interaction_mean_square, interaction_dof, len(dependent_var) - len(np.unique(independent_var1)) * len(np.unique(independent_var2)))\n",
    "\n",
    "print(\"P-value for Main Effect 1:\", pval_main1)\n",
    "print(\"P-value for Main Effect 2:\", pval_main2)\n",
    "print(\"P-value for Interaction Effect:\", pval_interaction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d615a8e-22f5-4d1b-8538-bf8a665d5b4c",
   "metadata": {},
   "source": [
    "3.Interpretation:\n",
    "\n",
    "If the p-value for either of the main effects is below your chosen significance level (e.g., 0.05), you can conclude that there is a significant main effect for that independent variable.\n",
    "If the p-value for the interaction effect is below your significance level, you can conclude that there is a significant interaction effect between the two independent variables.\n",
    "Remember that this is a simplified example and may need adjustments based on your specific data and requirements. Additionally, Python has various statistical packages that can make performing ANOVA easier, such as statsmodels, which provides more comprehensive tools for ANOVA analysis.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1ccfb9-a7e2-41de-98ae-9086c5b6f541",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7883d9-7a85-42ca-b654-430176e6c63b",
   "metadata": {},
   "source": [
    "In the context of a one-way ANOVA, the F-statistic is used to determine if there are significant differences in the means of three or more groups. The p-value associated with the F-statistic indicates the probability of observing the data if there are no significant differences between the groups. A lower p-value suggests stronger evidence against the null hypothesis (which assumes no significant differences), indicating that there are indeed differences between the groups.\n",
    "\n",
    "In your case, you obtained an F-statistic of 5.23 and a p-value of 0.02. This p-value is less than the commonly used significance level of 0.05, which means you have enough evidence to reject the null hypothesis and conclude that there are significant differences between at least some of the groups being compared.\n",
    "\n",
    "The interpretation of these results would be as follows:\n",
    "\n",
    "Null Hypothesis (H0): There are no significant differences between the means of the groups.\n",
    "Alternative Hypothesis (Ha): At least one group mean is different from the others.\n",
    "Since the p-value (0.02) is less than the significance level (commonly 0.05), you would reject the null hypothesis. This indicates that you have found evidence that there are differences between the groups. However, the ANOVA itself does not tell you which specific groups are different from each other.\n",
    "\n",
    "To identify which groups are different, you might consider performing post hoc tests (such as Tukey's HSD, Bonferroni, or Dunnett's test) to make pairwise comparisons between groups. These tests help determine which specific group means are significantly different from each other. The decision to use a particular post hoc test depends on the nature of your data and your specific research question.\n",
    "\n",
    "In summary, with an F-statistic of 5.23 and a p-value of 0.02, you can conclude that there are significant differences between the groups being compared. Further post hoc tests can be conducted to determine which specific groups are different from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96d9302-6bbd-4b81-8abf-b62bb223df3d",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ae1c47-2c4b-45bb-96aa-46a5940abc44",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA (Analysis of Variance) is an important consideration as it can affect the validity and reliability of your results. There are several methods to handle missing data in this context, each with its own potential consequences:\n",
    "\n",
    "Listwise Deletion (Complete Case Analysis): This approach involves removing any participant with missing data from the analysis. While it's straightforward, it can lead to biased results if the missing data are not missing completely at random (MCAR). This method can result in a reduced sample size and potentially introduce selection bias.\n",
    "\n",
    "Pairwise Deletion: This approach includes all available data for each analysis, without removing cases entirely. However, it can lead to biased results if the missing data are not MCAR. Additionally, it can inflate Type I error rates (false positives) and lead to reduced statistical power.\n",
    "\n",
    "Imputation: Imputation involves estimating missing values using various techniques. Common imputation methods include mean imputation, regression imputation, and multiple imputation.\n",
    "\n",
    "Mean Imputation: Replace missing values with the mean of the observed values for that variable. While simple, this can lead to an underestimation of standard errors and biased estimates if the data are not MCAR.\n",
    "Regression Imputation: Predict missing values using regression analysis based on other variables. This can be more accurate if there are relationships between variables, but it assumes that the relationships hold for the missing cases.\n",
    "Multiple Imputation: This is a more sophisticated method where multiple datasets are created, each with different imputed values based on the observed data and an imputation model. The results from these datasets are combined to provide more accurate estimates of parameters and standard errors. It's a recommended approach if missing data are a concern.\n",
    "Last Observation Carried Forward (LOCF) or Next Observation Carried Backward (NOCB): In time-series data, missing values can be replaced with the last observed value (LOCF) or the next observed value (NOCB). This approach assumes that the missing values don't change between observations, which might not always be appropriate.\n",
    "\n",
    "Model-Based Imputation: Impute missing data using statistical models that consider the relationships between variables. For instance, you could use a mixed-effects model to impute missing values based on observed patterns in the data.\n",
    "\n",
    "Potential consequences of using different methods:\n",
    "\n",
    "Bias: Incorrect handling of missing data can introduce bias into your results. If the missing data are not MCAR, imputing or deleting them inappropriately can lead to biased parameter estimates.\n",
    "\n",
    "Precision: Incorrect handling of missing data can lead to imprecise estimates of parameters and standard errors, affecting the reliability of your results.\n",
    "\n",
    "Power: Improper handling of missing data can reduce statistical power, making it harder to detect significant effects if they exist.\n",
    "\n",
    "Type I and Type II Errors: Inappropriate handling of missing data can affect Type I error rates (false positives) and Type II error rates (false negatives).\n",
    "\n",
    "Generalizability: If missing data are handled inappropriately, the results might not generalize well to the larger population.\n",
    "\n",
    "In summary, the choice of how to handle missing data in a repeated measures ANOVA should be driven by the characteristics of your data and the underlying assumptions about the missingness mechanism. Multiple imputation is generally considered a robust approach, as it accounts for uncertainty in imputed values and provides more accurate parameter estimates. However, it's important to consult with experts in your field and possibly consult statistical software documentation for specific guidance on handling missing data in your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33d0fa2-9535-4707-8b0c-f0fef852b3b4",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b46e71f-1a82-45d4-b9b5-7571f3ac81fe",
   "metadata": {},
   "source": [
    "After conducting an Analysis of Variance (ANOVA) and finding a significant difference among group means, post-hoc tests are used to determine which specific group pairs differ significantly from each other. Post-hoc tests are necessary because ANOVA only tells you that there is a significant difference somewhere among the groups, but it doesn't pinpoint where those differences occur. Here are some common post-hoc tests and when to use them:\n",
    "\n",
    "Tukey's Honestly Significant Difference (HSD):\n",
    "\n",
    "When to use: Tukey's HSD is used when you have conducted a one-way ANOVA and you want to compare all possible pairwise combinations of group means.\n",
    "Example: Suppose you are comparing the effectiveness of three different teaching methods (A, B, and C) on student performance. After performing ANOVA, you find a significant difference. You would then use Tukey's HSD to determine which pairs of teaching methods have significantly different effects.\n",
    "Bonferroni Correction:\n",
    "\n",
    "When to use: The Bonferroni correction is used when you are making multiple pairwise comparisons and you want to control for the increased risk of Type I error (false positives) that comes with multiple testing.\n",
    "Example: In a clinical trial, you are testing the efficacy of a new drug against three different control treatments. You want to compare the drug to each control separately. Since you are conducting multiple tests, you use the Bonferroni correction to adjust the significance level to maintain an acceptable overall error rate.\n",
    "Dunn's Test:\n",
    "\n",
    "When to use: Dunn's test is used in situations where you have conducted a non-parametric ANOVA (like the Kruskal-Wallis test) and want to perform post-hoc comparisons.\n",
    "Example: You are analyzing the performance of different brands of smartphones in terms of battery life (non-parametric data). After finding a significant difference with the Kruskal-Wallis test, you would use Dunn's test to determine which brands have significantly different battery life.\n",
    "Scheffe's Method:\n",
    "\n",
    "When to use: Scheffe's method is used when you have a complex experimental design with multiple factors and you want to compare group means while controlling for familywise error rate.\n",
    "Example: In a two-way ANOVA analyzing the effects of diet and exercise on weight loss, you want to compare specific combinations of diets and exercise regimes to identify significant differences. Scheffe's method would help you make these comparisons while accounting for multiple testing.\n",
    "Fisher's LSD (Least Significant Difference):\n",
    "\n",
    "When to use: Fisher's LSD is less conservative than methods like Tukey's HSD and can be used when you have a small number of comparisons to make and you're not concerned about controlling the overall Type I error rate.\n",
    "Example: You conducted an ANOVA to compare the yield of different fertilizer treatments on crop production. You want to know which specific treatments have significantly different yields, and you're not overly concerned about inflating the Type I error rate.\n",
    "Remember that the choice of post-hoc test depends on the nature of your data, your experimental design, and your goals in terms of controlling Type I error rates and making accurate pairwise comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5cdc47-219e-4bfc-8e00-462c05bfbc1c",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fd0e0ff-b00d-44c7-9624-3d8f100653cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (1.9.3)\n",
      "Requirement already satisfied: numpy<1.26.0,>=1.18.5 in /opt/conda/lib/python3.10/site-packages (from scipy) (1.23.5)\n",
      "F-statistic: 72.88372093023281\n",
      "p-value: 1.9363469432387716e-07\n",
      "Reject the null hypothesis. There are significant differences between the mean weight loss of the three diets.\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Example data (replace with actual data)\n",
    "diet_A = [1.5, 2.0, 1.8, 2.2, 1.9]  # List of weight loss values for Diet A\n",
    "diet_B = [2.5, 2.7, 2.3, 2.8, 2.6]  # List of weight loss values for Diet B\n",
    "diet_C = [0.8, 1.0, 0.9, 1.2, 1.1]  # List of weight loss values for Diet C\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Print the results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis. There are significant differences between the mean weight loss of the three diets.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. There is no significant differences between the mean weight loss of the three diets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7d0ccf-7a07-4909-9095-f92e824b375e",
   "metadata": {},
   "source": [
    "In this code, replace the example data lists with the actual weight loss values for each diet. The f_oneway function from scipy.stats calculates the F-statistic and p-value for the ANOVA test. The p-value indicates whether there are significant differences between the means of the groups (diets) or not. If the p-value is less than the chosen significance level (alpha), you can reject the null hypothesis and conclude that there are significant differences between the mean weight loss of the diets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e4a5bd-6dde-4b92-b578-40f5fef23ac0",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e4b29e9-cd46-4fd0-ab99-b739a80742d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               sum_sq    df         F    PR(>F)\n",
      "C(Software)                  1.334021   2.0  0.193670  0.824297\n",
      "C(Experience)                5.096305   1.0  1.479736  0.227223\n",
      "C(Software):C(Experience)    8.396750   2.0  1.219018  0.300694\n",
      "Residual                   289.301266  84.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "np.random.seed(42)\n",
    "\n",
    "n = 30  # Number of employees per group\n",
    "software = np.random.choice(['Program A', 'Program B', 'Program C'], size=n*3)\n",
    "experience = np.random.choice(['Novice', 'Experienced'], size=n*3)\n",
    "times = np.random.normal(loc=10, scale=2, size=n*3)  # Simulated completion times\n",
    "data = pd.DataFrame({'Software': software, 'Experience': experience, 'Time': times})\n",
    "# Fit the ANOVA model\n",
    "model = ols('Time ~ C(Software) + C(Experience) + C(Software):C(Experience)', data=data).fit()\n",
    "anova_table = anova_lm(model, typ=2)\n",
    "\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461b438c-fae8-43ad-843c-6a34efdbfd71",
   "metadata": {},
   "source": [
    "This will provide you with an ANOVA table that includes the main effects and interaction effects.\n",
    "\n",
    "Interpret the Results:\n",
    "In the ANOVA table, you will find the F-statistics and p-values for each factor and their interactions. Here's how to interpret the results:\n",
    "\n",
    "If the p-value for a factor is less than your chosen significance level (e.g., 0.05), you can conclude that there is a significant main effect of that factor.\n",
    "If the p-value for an interaction term is significant, it indicates that the interaction effect is significant, implying that the combined effect of the two factors is not simply additive.\n",
    "Remember that you should carefully examine the results in the context of your research question and domain knowledge. Additionally, performing post hoc tests (e.g., Tukey's HSD) can help identify which specific groups are different from each other after finding significant main effects or interactions.\n",
    "\n",
    "Note: Make sure to replace the simulated data with your actual data and adjust the code as needed for your specific dataset and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b0db32-55da-470d-86bf-47598d8cdd32",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2622b7ee-b1fb-4b55-8a8b-6dc96533dbc4",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Generate some example data for control and experimental groups\n",
    "np.random.seed(0)\n",
    "control_group = np.random.normal(70, 10, 50)  # Mean: 70, Standard Deviation: 10\n",
    "experimental_group = np.random.normal(75, 10, 50)  # Mean: 75, Standard Deviation: 10\n",
    "\n",
    "# Perform a two-sample t-test\n",
    "t_stat, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "\n",
    "print(\"Two-sample t-test results:\")\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Check if the results are significant\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"There is a significant difference between the groups.\")\n",
    "else:\n",
    "    print(\"There is no significant difference between the groups.\")\n",
    "\n",
    "# If results are significant, perform a post-hoc test (e.g., Tukey's HSD)\n",
    "if p_value < alpha:\n",
    "    from statsmodels.stats.multicomp import MultiComparison\n",
    "    data = np.concatenate((control_group, experimental_group))\n",
    "    group_labels = ['Control'] * len(control_group) + ['Experimental'] * len(experimental_group)\n",
    "    mc = MultiComparison(data, group_labels)\n",
    "    result = mc.tukeyhsd()\n",
    "    print(\"\\nPost-hoc test results:\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ab29c6-2d8e-4b08-a30e-478586be5385",
   "metadata": {},
   "source": [
    "Please note that in this example, I've generated example data for the control and experimental groups using normal distributions with different means. In your case, you would replace this data with your actual test scores for the two groups.\n",
    "\n",
    "The code uses the ttest_ind function from scipy.stats to perform the two-sample t-test and the MultiComparison class from statsmodels.stats.multicomp to perform the post-hoc test (Tukey's HSD in this case). The post-hoc test helps identify which specific groups differ significantly from each other after finding a significant difference in the initial t-test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8eddea-70cb-42bd-94b6-2a3e8584c35b",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0440762-8f18-4287-96e6-b0aac5614d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in /opt/conda/lib/python3.10/site-packages (0.13.5)\n",
      "Requirement already satisfied: pandas>=0.25 in /opt/conda/lib/python3.10/site-packages (from statsmodels) (1.5.2)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from statsmodels) (0.5.3)\n",
      "Requirement already satisfied: scipy>=1.3 in /opt/conda/lib/python3.10/site-packages (from statsmodels) (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from statsmodels) (1.23.5)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from statsmodels) (22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25->statsmodels) (2022.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n",
      "               Anova\n",
      "===================================\n",
      "      F Value Num DF  Den DF Pr > F\n",
      "-----------------------------------\n",
      "Store  2.1584 2.0000 58.0000 0.1247\n",
      "===================================\n",
      "\n",
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05  \n",
      "=======================================================\n",
      " group1  group2 meandiff p-adj   lower    upper  reject\n",
      "-------------------------------------------------------\n",
      "Store A Store B  -4.9333 0.8968 -31.3731 21.5064  False\n",
      "Store A Store C -21.3667 0.1372 -47.8064  5.0731  False\n",
      "Store B Store C -16.4333 0.3045 -42.8731 10.0064  False\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Create a DataFrame with sales data for each store on each day\n",
    "data = {\n",
    "    'Day': np.repeat(np.arange(1, 31), 3),\n",
    "    'Store': np.tile(['Store A', 'Store B', 'Store C'], 30),\n",
    "    'Sales': np.random.randint(50, 200, 90)  # Replace with your actual sales data\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform repeated measures ANOVA\n",
    "aovrm = AnovaRM(df, 'Sales', 'Day', within=['Store'])\n",
    "results = aovrm.fit()\n",
    "print(results)\n",
    "\n",
    "# Perform post-hoc Tukey's HSD test\n",
    "posthoc = pairwise_tukeyhsd(df['Sales'], df['Store'])\n",
    "print(posthoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18d8aaa-a448-4a0f-8abb-3c025e6b00a8",
   "metadata": {},
   "source": [
    "Replace the Sales column values with your actual sales data for each day and store. The code above creates a DataFrame, performs a repeated measures ANOVA, and then performs a post-hoc Tukey's Honestly Significant Difference (HSD) test to determine which store(s) have significant differences in sales.\n",
    "\n",
    "Make sure you understand the assumptions behind ANOVA and post-hoc tests, as well as the interpretation of the results. Also, consider checking the documentation of the statsmodels library for any updates or additional details.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
